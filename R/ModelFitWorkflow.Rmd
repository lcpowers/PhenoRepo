---
title: "Workflow through Model Fitting"
output: html_document
---

## To do's:
# Run robust gridsearch


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(root.dir="/home/claire/Git/PhenoRepo/")
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

### Packages
```{r packages, message=FALSE}
rm(list=ls())

library(here)
library(lubridate)
library(tidyverse)
library(neon4cast)
library(neonUtilities)
library(zoo)
library(imputeTS)
library(forecast)

source("R/calcGDDfun.R")
source("R/WarmModel.R")
source("R/WarmModelForecast.R")
source("R/gridsearch_Casey.R")
source("R/ssq_phenomod.R")
```

## Update and read-in target data, then remove leading NAs and fill in others
```{r targetDate}
# Update target data if not yet updated today 
target_fp <- "data/pheno/phenology-targets.csv.gz"

if(as.Date(file.info(target_fp)$ctime)!=Sys.Date()) {
  print("Downloading updated target data")
    download.file("https://data.ecoforecast.org/targets/phenology/phenology-targets.csv.gz",
              target_fp)
    }

targets_raw <- read.csv(target_fp,header=TRUE)
targets_raw$siteID <- as.factor(targets_raw$siteID)
targets_raw$time <- as.Date(targets_raw$time)

sites <- unique(targets_raw$siteID)
targets <- NULL

# Remove rows with leading NAs and fill in other NAs in gcc_90
for(site in sites){
  site_targs <- filter(targets_raw,siteID==site)
  # Remove rows with leading NAs
  while(is.na(site_targs$gcc_90[1])){
    site_targs <- site_targs[2:nrow(site_targs),]
  }

  if(site=='UKFS') {site_targs$gcc_90 <- tsclean(site_targs$gcc_90,replace.missing = F,lambda = 'auto') %>% as.numeric()}
 
  # Fill in other NAs
  x <- zoo(site_targs$gcc_90,site_targs$time)
  x <- na.interp(site_targs$gcc_90) %>% as.numeric()
  site_targs$gcc_90 <- x

  targets <- rbind(targets,site_targs)
  rm(site_targs,x)
}

targets$time <- as.Date(targets$time)
targets$day <- yday(targets$time)
targets$year <- substr(targets$time,1,4)

# Remove extra vars from Global Env
rm(target_fp,site,targets_raw)
```


## Update or read in temperature data
```{r NEONtempdata}

## Update NEON temperature data and read in. This will take A WHILE (2 hrs?), so only run this line if you really want to update weather data, otherwise keep it commented out and run the line the reads in the most recent temperature data

# source("R/GetNEONwxdata.R")
neon_wx <- read_csv("data/drivers/neon/temps_allsites.csv") %>% 
  select(siteID,date,daily_mean,daily_min,daily_max) %>% 
  mutate(source='neon') %>% 
  filter(date >= min(targets$time))

## Update NOAA weather data. This will take a minute or two, but shouldn't take longer
## When it finishes, should be a dataframe called noaa_wx in the global env
# source("R/GetNOAAForecastData.R")

## Or read in most recent pull of data
noaa_wx <- read_csv("./data/drivers/noaa/noaa_temp_4cast_2021-05-05.csv")
noaa_wx <- noaa_wx %>% 
  select(siteID,date,daily_mean,daily_min,daily_max) %>% 
  mutate(source='noaa')

all_wx <- rbind(neon_wx,noaa_wx)
rm(neon_wx,noaa_wx)

# Apply GDD function which will fill in missing temp data and calculate GDD values
GDD <- calcGDDfun(temp_df=all_wx,targets_df = targets,int_method = "spline")

# Add in day of year
GDD$day <- yday(GDD$date)

# For each site, check that target dates have matching weather dates
for(site in sites){
  
  targs <- filter(targets,siteID==site & time <= Sys.Date())
  wx <- filter(GDD,siteID==site & date <= Sys.Date())
  x = as.Date(setdiff(as.Date(targs$time),as.Date(wx$date)))
  
  if(length(x)>0) print(paste0("Targets for ",site," missing wx for",x))
  
}
rm(all_wx,wx,x,site,targs)
```


## I. Model fitting   
### a. Parameter fitting
```{r gridsearch}

sites <- unique(targets$siteID) %>% as.character()
#sites = "GRSM"
site = sites[6]

# Start and end dates of warm period
spring_date <- "-02-24"
fall_date <- "-09-01"
n_params <- 5 # Number of parameters being stored for the model

# Dataframe to store fitted parameters for each site
params_df <- as.data.frame(matrix(data=NA,
                                  nrow = n_distinct(sites),
                                  ncol=n_params+1))
colnames(params_df)<-c("siteID","G_init","a","b","green_up","G_max")

# Start parameter fitting loop
for(site in sites){

  # Filter target data for site and warm period
  site_targs <- targets %>% 
    filter(siteID==site) %>% # Get site data
    arrange(time) %>%  # make sure arranged by time
    filter(time>=as.Date(paste0(year(time),spring_date)),
           time<=as.Date(paste0(year(time),fall_date)))
  
  # Filter weather data for site and warm period
  site_GDD <- GDD %>% 
    filter(siteID==site) %>% # Get site data
    arrange(date) %>%  # make sure arranged by time
    filter(date>=as.Date(paste0(year(date),spring_date)),
           date<=as.Date(paste0(year(date),fall_date)),
           date<=max(site_targs$time))

  # Remove 2017 for GRSM 
  if (site == "GRSM"){
    site_targs <- filter(site_targs, time >= as.Date("01-01-18","%m-%d-%y"))
    site_GDD <- filter(site_GDD, date >= as.Date("01-01-18","%m-%d-%y"))
  }

  # Find average GCC value in first seven days
  avg_G_init = mean(site_targs$gcc_90[1:7])
  
  # Find average maximum GCC 
  avg_G_max = site_targs %>% 
    group_by(year) %>% 
    filter(year != 2021) %>% # Maybe don't filter this for all sites? 
    summarise(maxGCC=max(gcc_90)) %>% 
    summarise(avg_maxGCC=mean(maxGCC)) %>% 
    as.numeric()
  
  # list of parameter ranges                             
  pvecs <- list(G_init = avg_G_init,  # GCC guess = avg first 7 days of targets
              a=seq(0,0.01,length.out=10),   # green-up: fast growth
              b=seq(0,0.2,length.out=10),  # maturation
              green_up=seq(10,70,length.out=10),   # Spring transition
              G_max = avg_G_max)  # Summer transition = max GCC avg each year
  
  # First pass at parameter fitting using gridsearch and SSQ
  gridsearch_fit <- gridsearch(pvecs, ssq_phenmod, y=site_targs$gcc_90, GDD=site_GDD, spring_date=spring_date)
  
  # SSQ: Set of starting parameters for optim to use
  # SSQ OPTIM FIT
  optim_starts <- c(gridsearch_fit$par["G_init"],
                    gridsearch_fit$par["a"],
                    gridsearch_fit$par["b"],
                    gridsearch_fit$par["green_up"],
                    gridsearch_fit$par["G_max"])
  optim_fit <- optim(optim_starts, ssq_phenmod, y=site_targs$gcc_90, GDD=site_GDD, spring_date=spring_date)
  
  # Store results in dataframe
  params_df$siteID[which(sites==site)] <- site
  params_df$G_init[which(sites==site)] = optim_fit$par["G_init"]
  params_df$a[which(sites==site)] = optim_fit$par["a"]
  params_df$b[which(sites==site)] = optim_fit$par["b"]
  params_df$green_up[which(sites==site)] = optim_fit$par["green_up"]
  params_df$G_max[which(sites==site)] = optim_fit$par["G_max"]
  
  # Plot results
  # GDD Warm Model Results
  G_init = optim_fit$par["G_init"]
  a = optim_fit$par["a"]
  b = optim_fit$par["b"]
  green_up = optim_fit$par["green_up"]
  G_max = optim_fit$par["G_max"]
  
  model_results <-  WarmModel(site_GDD,G_init,a,b,green_up,G_max,spring_date = spring_date)
  colnames(model_results)[2] <- "gcc_90"
  model_results$day <- yday(model_results$date)
  fitPlot <- ggplot() +
        geom_point(data = site_targs, aes(x = as.Date(time), y = gcc_90), color = "springgreen4") +
        geom_point(data=model_results, aes(x = date, y = gcc_90), color = "red") +
        labs(x="Day of year",y="GCC 90",title=paste0(site, " Model Fit")) +
        theme_classic(base_size = 15)
  
  print(fitPlot)
}

write_csv(params_df,"data/model/model_params.csv")
```

Plot gridsearch surface
```{r}




```


### B. Uncertainty estimation with cross validation
```{r CrossValidation}

sites <- unique(targets$siteID) %>% as.character()
site = sites[6]

# Start and end dates of warm period
spring_date <- "-02-24"
fall_date <- "-09-01"

# Dataframe to store fitted parameters for each site
cv_params_df <- NULL

# Start a data.frame to store errors, that contains a column for date. The
# temporary error data.frames in each loop will be merged into this one using date as the join key
error_df <- data.frame(date=seq(as.Date(paste0('2021',spring_date)),
                               as.Date(paste0('2021',fall_date)),by='day'))

# Start parameter fitting loop
for(site in sites){
  
  # Filter target data for site and warm period
  site_targs <- targets %>% 
    filter(siteID==site) %>% # Get site data
    arrange(time) %>%  # make sure arranged by time
    filter(time>=as.Date(paste0(year(time),spring_date)),
           time<=as.Date(paste0(year(time),fall_date)))
  
  # Filter weather data for site and warm period
  site_GDD <- GDD %>% 
    filter(siteID==site) %>% # Get site data
    arrange(date) %>%  # make sure arranged by time
    filter(date>=as.Date(paste0(year(date),spring_date)),
           date<=as.Date(paste0(year(date),fall_date)),
           date<=max(site_targs$time))

  # Remove 2017 for GRSM 
  if (site == "GRSM"){
    site_targs <- filter(site_targs, time >= as.Date("01-01-18","%m-%d-%y"))
    site_GDD <- filter(site_GDD, date >= as.Date("01-01-18","%m-%d-%y"))
  }

  years <- unique(site_targs$year)
  for(yeari in years){
  
    training_targs <- filter(site_targs,year!=yeari)
    test_targs <- filter(site_targs,year==yeari)
    
    training_GDD <- filter(site_GDD,year!=yeari)
    test_GDD <- filter(site_GDD,year==yeari)
    
    # Find average GCC value in first seven days
    avg_G_init = mean(training_targs$gcc_90[1:7])
    
    # Find average maximum GCC 
    avg_G_max = training_targs %>% 
      group_by(year) %>% 
      filter(year != 2021) %>% # Maybe don't filter this for all sites? 
      summarise(maxGCC=max(gcc_90)) %>% 
      summarise(avg_maxGCC=mean(maxGCC)) %>% 
      as.numeric()
    
    # list of parameter ranges                             
    pvecs <- list(G_init = avg_G_init,  # GCC guess = avg first 7 days of targets
              a=seq(0,0.01,length.out=10),   # green-up: fast growth
              b=seq(0,0.2,length.out=10),  # maturation
              green_up=seq(30,70,length.out=10),   # Spring transition
              G_max = avg_G_max)  # Summer transition = avg date of peak GCC
    
    # First pass at parameter fitting using gridsearch and SSQ
    gridsearch_fit <- gridsearch(pvecs, ssq_phenmod,y=training_targs$gcc_90,GDD=training_GDD,spring_date=spring_date)
    
    # SSQ: Set of initial parameters for optim to use
    optim_starts <- c(gridsearch_fit$par["G_init"],
                      gridsearch_fit$par["a"],
                      gridsearch_fit$par["b"],
                      gridsearch_fit$par["green_up"],
                      gridsearch_fit$par["G_max"])
    optim_fit <- optim(optim_starts,ssq_phenmod,y=training_targs$gcc_90, GDD = training_GDD,spring_date=spring_date)
    
    # Store parameters in data frame
    tmp_params <- data.frame(siteID=site,
                             test_year = yeari,
                             G_init = optim_fit$par["G_init"],
                             a = optim_fit$par["a"],
                             b = optim_fit$par["b"],
                             green_up = optim_fit$par["green_up"],
                             G_max = optim_fit$par["G_max"])
    cv_params_df <- rbind(cv_params_df,tmp_params)
    
    # Make list of parameters to feed into WarmModelForecast function
    params <- list(G_init = optim_fit$par["G_init"],
                   a = optim_fit$par["a"],
                   b = optim_fit$par["b"],
                   green_up = optim_fit$par["green_up"],
                   G_max = optim_fit$par["G_max"],
                   spring_date=spring_date)
    
    yeari_forecast <- WarmModelForecast(params=params,
                                        GDD = test_GDD,
                                        targets = test_targs,
                                        spring_date = spring_date,
                                        cross_validation = TRUE)
    
    tmp_error <- yeari_forecast %>% select(time,error)
                    
    error_df <- merge(error_df,tmp_error,by.x='date',by.y='time' ,all=TRUE)
    colnames(error_df)[ncol(error_df)] <- c(paste0(site,as.character(yeari)))
    rm(tmp_params,tmp_error)
    
    }

  }

```


```{r}
ggplot(yeari_forecast,aes(x=time))+
  geom_point(aes(y=obs_gcc_90))+
  geom_point(aes(y=pred_gcc_90))+
  # geom_ribbon((aes(ymax=pred_gcc_90+abs(deviation),ymin=pred_gcc_90-abs(deviation))),alpha=0.5)+
  theme_classic()
```

