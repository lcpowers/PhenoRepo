---
title: "Workflow through Model Fitting"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(root.dir="/home/claire/Git/PhenoRepo/")
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

### Packages
```{r packages, message=FALSE}
rm(list=ls())

library(here)
library(lubridate)
library(tidyverse)
library(neon4cast)
library(neonUtilities)
library(zoo)
library(imputeTS)

source("R/calcGDDfun.R")
source("R/WarmModel.R")
source("R/gridsearch_Casey.R")
source("R/ssq_phenomod.R")
```

## Update and read-in target data, then remove leading NAs and fill in others
```{r targetDate}
# Update target data if not yet updated today 
target_fp <- "data/pheno/phenology-targets.csv.gz"

if(as.Date(file.info(target_fp)$ctime)!=Sys.Date()) {
  print("Downloading updated target data")
    download.file("https://data.ecoforecast.org/targets/phenology/phenology-targets.csv.gz",
              target_fp)
    }

targets_raw <- read.csv(target_fp,header=TRUE) 

sites <- unique(targets_raw$siteID)
targets <- NULL

# Remove rows with leading NAs and fill in other NAs in gcc_90
for(site in sites){
  site_targs <- filter(targets_raw,siteID==site)
  
  # Remove rows with leading NAs
  while(is.na(site_targs$gcc_90[1])){
    site_targs <- site_targs[2:nrow(site_targs),]
  }
  
  # Fill in other NAs
  x <- zoo(site_targs$gcc_90,site_targs$time)
  x <- na_interpolation(x, option = "spline") %>% as.data.frame() %>% rownames_to_column()
  site_targs$gcc_90 <- x$.
  
  targets <- rbind(targets,site_targs)
  rm(site_targs,x)
}
# Remove extra vars from Global Env
rm(target_fp,site,targets_raw)
```

## Update or read in temperature data
```{r NEONtempdata}

## Update NEON temperature data and read in. This will take A WHILE (2 hrs?), so only run this line if you really want to update weather data, otherwise keep it commented out and run the line the reads in the most recent temperature data
# source("R/GetNEONwxdata.R")
neon_wx <- read_csv("data/drivers/neon/temps_allsites.csv") %>% 
  select(siteID,date,daily_mean,daily_min,daily_max) %>% 
  mutate(source='neon') %>% 
  filter(date >= min(targets$time))

## Update NOAA weather data. This will take a minute or two, but shouldn't take longer
## When it finishes, should be a dataframe called noaa_wx in the global env
# source("R/GetNOAAForecastData.R")

## Or read in most recent pull of data
noaa_wx <- read_csv("./data/drivers/noaa/noaa_temp_4cast_2021-05-05.csv")
noaa_wx <- noaa_wx %>% 
  select(siteID,date,daily_mean,daily_min,daily_max) %>% 
  mutate(source='noaa')

all_wx <- rbind(neon_wx,noaa_wx)
rm(neon_wx,noaa_wx)

# Apply GDD function which will fill in missing temp data and calculate GDD values
GDD_df <- calcGDDfun(temp_df=all_wx,targets_df = targets,int_method = "spline")

# For each site, check that target dates have matching weather dates
for(site in sites){
  
  targs <- filter(targets,siteID==site & time <= Sys.Date())
  wx <- filter(GDD_df,siteID==site & date <= Sys.Date())
  x = as.Date(setdiff(as.Date(targs$time),as.Date(wx$date)))
  
  if(length(x)>0) print(paste0("Targets for ",site," missing wx for",x))
  
}

```

## I. Model fitting   
### a. Parameter fitting
```{r gridsearch}
## Is there any reason for this list of vectors to be different for different sites?

# list of parameter ranges
pvecs <- list(G_init = mean(targets$gcc_90[1:7]),  # GCC guess = avg first 7 days of targets
              a=seq(0,0.01,length.out=5),   # green-up: fast growth
              b=seq(0,0.001,length.out=5),  # maturation
              t1=seq(30,70,length.out=5),   # Spring transition
              t2= )  # Summer transition

## Could start for loop through sites here. What other info do we need for this? Check new method to estimate average day

# Feed in parameter list, ssq function, target data, input data
fit <- gridsearch(pvecs, ssq_phenmod, y=targets$gcc_90, GDD = GDD)

## Finish data fitting using optim function
starts <- c(fit$par["G_init"],
            fit$par["a"],fit$par["b"],
            fit$par["t1"],fit$par["t2"])

fit_fin <- optim( starts, ssq_phenmod, y=targets$gcc_90, GDD = GDD)

## End for loop here and write site specific params to global environment and/or output folder for model params, which could then be used in the Forecast workflow

```

### B. Uncertainty by replacing ssq with nll or with cross validation? 


