---
title: "Forecast Workflow"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(root.dir="/home/claire/Git/PhenoRepo/")
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

### Packages
```{r packages}
rm(list=ls())

# remotes::install_github("cboettig/prov")
library(contentid)
library(prov)
library(aws.s3)
library(here)
library(lubridate)
library(tidyverse)
library(neon4cast)
library(neonUtilities)
library(zoo)
library(imputeTS)
library(reshape2)

source("R/NEONscripts/publish.R")
source("R/WarmModelForecast.R")
source("R/calcGDDfun.R")

team_ID = "CU_Pheno" 
EFI_theme="phenology"
forecast_file=paste0("~/Desktop/CurrentProjects/TeamRotation/PhenoRepo/data/forecasts/",EFI_theme,"-",Sys.Date(),"-",team_ID,".csv")
```


## I. Read in target data
```{r targetData}
# Update target data if not yet updated today 
target_fp <- "data/pheno/phenology-targets.csv.gz"

if(as.Date(file.info(target_fp)$ctime)!=Sys.Date()) {
  print("Downloading updated target data")
    download.file("https://data.ecoforecast.org/targets/phenology/phenology-targets.csv.gz",
              target_fp)
    }

targets <- read.csv(target_fp,header=TRUE) %>% 
  filter(time >= "2021-01-01") %>% 
  mutate(siteID=as.factor(siteID),
         time=as.Date(time))

model_params <- read_csv("data/model/model_params.csv")
sites <- unique(targets$siteID)
```


## II. Read in temperature data and get GDD values -- Need NEON data for current year and 35-day forecasted NOAA data.
```{r wxData}
## Update NEON temperature data and read in. This will take A WHILE (2 hrs?), so only run this line if you really want to update weather data, otherwise keep it commented out and run the line the reads in the most recent temperature data

# source("R/GetNEONwxdata.R")
neon_wx <- read_csv("data/drivers/neon/temps_allsites.csv") %>%
  select(siteID,date,daily_mean,daily_min,daily_max) %>%
  mutate(source='neon') %>%
  filter(date >= "2021-01-01")

## Update NOAA weather data. This will take a minute or two, but shouldn't take longer
## When it finishes, should be a dataframe called noaa_wx in the global env
source("R/GetNOAAForecastData.R")
noaa_wx <- read_csv(paste0("./data/drivers/noaa/noaa_temp_4cast_",Sys.Date(),".csv"))

## Or read in most recent pull of data. Last pull of new data was 2021-05-09. 
# IF THIS LINE (below) GIVES AN ERROR, PROBABLY NEED TO RUN line 77 FOR NEW DATA
# noaa_wx <- read_csv(paste0("./data/drivers/noaa/noaa_temp_4cast_",Sys.Date(),".csv"))

# Either way, run this
noaa_wx <- noaa_wx %>%
  select(siteID,date,daily_mean,daily_min,daily_max) %>%
  mutate(source='noaa')

all_wx <- rbind(neon_wx,noaa_wx)
rm(neon_wx,noaa_wx)

# Apply GDD function which will fill in missing temp data and calculate GDD values
GDD <- calcGDDfun(temp_df=all_wx,targets_df = targets,int_method = "spline")

# Add in day of year
GDD$day <- yday(GDD$date)

# For each site, check that target dates have matching weather dates
for(site in sites){

  targs <- filter(targets,siteID==site & time <= Sys.Date())
  wx <- filter(GDD,siteID==site & date <= Sys.Date())
  x = as.Date(setdiff(as.Date(targs$time),as.Date(wx$date)))

  if(length(x)>0) print(paste0("Targets for ",site," missing wx for",x))

}
rm(all_wx,wx,x,site,targs)

GDD <- filter(GDD,date>=Sys.Date())
```


## III. Forecast using NOAA temperature data -- make sure it's updated. 
```{r forecastGCC}
forecast_df <- NULL
spring_date = str_sub(string = Sys.Date(),start = 5,end = 10)

for(site in sites){
  
  site_targs <- targets %>% filter(siteID==site) %>% filter(time>=(Sys.Date()-7))
  site_GDD <- GDD %>% filter(siteID==site&date>=Sys.Date())
  
  site_params <- model_params %>% filter(siteID==site)
  site_params <- list(G_init = mean(site_targs$gcc_90,na.rm = T),
                     a = site_params$a[1],
                     b = site_params$b[1],
                     green_up = site_params$green_up[1],
                     G_max = site_params$G_max[1],
                     spring_date=spring_date)
  
  tmp_forecast <- WarmModelForecast(params = site_params, GDD=site_GDD, targets=site_targs, spring_date = spring_date,cross_validation = FALSE)
  tmp_forecast$siteID <- site
  tmp_forecast <- select(tmp_forecast,c(time=date,siteID,'gcc_90'=pred_gcc_90)) %>% 
    mutate(gcc_sd=NA,
           forecast_day=seq(1:nrow(.))) 
  forecast_df <- rbind(forecast_df,tmp_forecast)
  rm(tmp_forecast,site_params,site_targs,site_GDD)
  
}

```


# IV. Add uncertainty estimate
```{r addUncertainty}

# Read in error csv produced at the end of model workflow
error_df <- read_csv("data/model/model_errors.csv") %>% 
  mutate(forecast_day = seq(1:nrow(.)))

# Restructure error df from wide to long format
error_melt <- melt(error_df,id.vars = c("dayofyear","forecast_day"), value.name = "deviation") %>% 
  mutate(siteID = as.factor(str_sub(variable,1,4)),
         year=str_sub(variable,5,8)) %>% 
  select(dayofyear,forecast_day,siteID,year,deviation) %>% 
  filter(complete.cases(.)) # Remove any rows with NAs / Keep complete rows
  
MSQerror_df <- error_melt %>% 
  group_by(forecast_day,siteID) %>% # For each forecast day....
  summarise(MSQerror = mean(deviation^2)) #...find the mean square error of the deviations (y.obs-y.pred)

# Create simple linear regression model of errors using forecast_day as predictor variable
error_lm <- lm(MSQerror~forecast_day+siteID,data=subset(MSQerror_df,forecast_day<=50))
summary(error_lm)

# Add error to forecast df
forecast_df$gcc_sd <- predict(error_lm, newdata = forecast_df)*50
```


# V. Plot forecasted GCC with targets and uncertainty
```{r plotForecast}
# Read full targets DF in to rbind to forecasted gcc values and plot

targets <- read.csv(target_fp,header=TRUE) %>% 
  mutate(time = as.Date(time),
         source=as.factor("targets"),
         siteID = as.factor(siteID))
forecast_df$source<-"forecast"

# Bind with targets, but skip forecast_day column
all_gcc <- rbind(targets,forecast_df[,c(1:4,6)]) %>% 
  mutate(year = year(time)) # Add year column to subset plot
  
ggplot(subset(all_gcc,time>="2020-01-01"), aes(x=time,y=gcc_90))+
  geom_point(aes(color=source),alpha=0.9)+
  geom_ribbon(data = subset(all_gcc,time>="2021-05-05"),
              mapping = aes(x=time,ymin=gcc_90-gcc_sd,ymax=gcc_90+gcc_sd,color=source,fill=source),alpha=0.75)+
  facet_wrap(~siteID)+
  theme_classic(base_size = 18)+
  theme(legend.text = element_text(size=20))+
  scale_color_manual(values=c("springgreen4","coral3"),labels=c("Observed","Forecasted"))+
  scale_fill_manual(values=c("springgreen4","coral3"),labels=c("Observed","Forecasted"))+
  scale_x_date(date_breaks="1 year", date_labels = "%Y")+
  labs(x="Year",y="Green Chromatic Coordinate (GCC)",color="",fill="")

ggsave("Figures/forecasts.png", height = 10,width = 15,dpi=400)
```


# VI. Get into correct format for succesful submission
```{r formatForSubmit}

submit_df <- all_gcc %>% 
  filter(time>=(Sys.Date()-1)) %>% 
  select(time,siteID,gcc_90,gcc_sd) %>% 
  melt(id.vars=c("time","siteID"),
       variable.name="statistic",
       value.name = "gcc_90")%>% 
  mutate(forecast=1,
         obs_flag=2,
         data_assimilation=0)
submit_df$statistic <- ifelse(submit_df$statistic=="gcc_90","mean","sd")
submit_df$statistic <- as.character(submit_df$statistic)

write_csv(submit_df,forecast_file)

```


# VII. Create metadata file
```{r metadata}

metadata_yaml <- paste0("~/Desktop/CurrentProjects/TeamRotation/PhenoRepo/data/forecasts/",EFI_theme,"-",Sys.Date(),"-",team_ID,".yml")

create_model_metadata(forecast_file)
write_metadata_eml(forecast_file=forecast_file,
                   metadata_yaml=metadata_yaml,
                   forecast_issue_time = Sys.Date(),
                   forecast_iteration_id = "2")

```


# VIII. Submit forecast
```{r submitForecast}
Sys.setenv("AWS_DEFAULT_REGION" = "data",
           "AWS_S3_ENDPOINT" = "ecoforecast.org")

aws.s3::put_object(file=forecast_file, bucket="submissions")
```


Extra stuff

### Need these set to submit?
```{r submitVars}
## Set the following  env vars: 
# AWS_SECRET_ACCESS_KEY=""
# AWS_DEFAULT_REGION="data"
# AWS_S3_ENDPOINT="ecoforecast.org"
```
