---
title: "Forecast Workflow"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(root.dir="/home/claire/Git/PhenoRepo/")
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

### Packages
```{r packages}
rm(list=ls())

# remotes::install_github("cboettig/prov")
library(contentid)
library(prov)
library(aws.s3)
library(here)
library(lubridate)
library(tidyverse)
library(neon4cast)
library(neonUtilities)
library(zoo)
library(imputeTS)

source("R/NEONscripts/publish.R")
source("R/WarmModelForecast.R")
source("R/calcGDDfun.R")
```


### Need these set to submit
```{r submitVars}
## Set the following  env vars: 
# AWS_SECRET_ACCESS_KEY=""
# AWS_DEFAULT_REGION="data"
# AWS_S3_ENDPOINT="ecoforecast.org"
```


## I. Read in target data
```{r targetData}
# Update target data if not yet updated today 
target_fp <- "data/pheno/phenology-targets.csv.gz"

if(as.Date(file.info(target_fp)$ctime)!=Sys.Date()) {
  print("Downloading updated target data")
    download.file("https://data.ecoforecast.org/targets/phenology/phenology-targets.csv.gz",
              target_fp)
    }

targets <- read.csv(target_fp,header=TRUE) %>% 
  filter(time >= "2021-01-01") %>% 
  mutate(siteID=as.factor(siteID),
         time=as.Date(time))

model_params <- read_csv("data/model/model_params.csv")
sites <- unique(targets$siteID)
```


## II. Read in temperature data and get GDD values -- Need NEON data for current year and 35-day forecasted NOAA data.
```{r wxData}
## Update NEON temperature data and read in. This will take A WHILE (2 hrs?), so only run this line if you really want to update weather data, otherwise keep it commented out and run the line the reads in the most recent temperature data

# source("R/GetNEONwxdata.R")
neon_wx <- read_csv("data/drivers/neon/temps_allsites.csv") %>%
  select(siteID,date,daily_mean,daily_min,daily_max) %>%
  mutate(source='neon') %>%
  filter(date >= "2021-01-01")

## Update NOAA weather data. This will take a minute or two, but shouldn't take longer
## When it finishes, should be a dataframe called noaa_wx in the global env
# source("R/GetNOAAForecastData.R")
# noaa_wx <- read_csv(paste0("./data/drivers/noaa/noaa_temp_4cast_",Sys.Date(),".csv"))

## Or read in most recent pull of data. Last pull of new data was 2021-05-09. 
# IF THIS LINE (below) GIVES AN ERROR, PROBABLY NEED TO RUN line 77 FOR NEW DATA
noaa_wx <- read_csv(paste0("./data/drivers/noaa/noaa_temp_4cast_",Sys.Date(),".csv"))

# Either way, run this
noaa_wx <- noaa_wx %>%
  select(siteID,date,daily_mean,daily_min,daily_max) %>%
  mutate(source='noaa')

all_wx <- rbind(neon_wx,noaa_wx)
rm(neon_wx,noaa_wx)

# Apply GDD function which will fill in missing temp data and calculate GDD values
GDD <- calcGDDfun(temp_df=all_wx,targets_df = targets,int_method = "spline")

# Add in day of year
GDD$day <- yday(GDD$date)

# For each site, check that target dates have matching weather dates
for(site in sites){

  targs <- filter(targets,siteID==site & time <= Sys.Date())
  wx <- filter(GDD,siteID==site & date <= Sys.Date())
  x = as.Date(setdiff(as.Date(targs$time),as.Date(wx$date)))

  if(length(x)>0) print(paste0("Targets for ",site," missing wx for",x))

}
rm(all_wx,wx,x,site,targs)

GDD <- filter(GDD,date>=Sys.Date())
```


## III. Forecast using NOAA temperature data -- make sure it's updated. 
```{r forecastGCC}
forecast_df <- NULL
spring_date = str_sub(string = Sys.Date(),start = 5,end = 10)

for(site in sites){
  
  site_targs <- targets %>% filter(siteID==site) %>% filter(time>=(Sys.Date()-7))
  site_GDD <- GDD %>% filter(siteID==site&date>=Sys.Date())
  
  site_params <- model_params %>% filter(siteID==site)
  site_params <- list(G_init = mean(site_targs$gcc_90,na.rm = T),
                     a = site_params$a[1],
                     b = site_params$b[1],
                     green_up = site_params$green_up[1],
                     G_max = site_params$G_max[1],
                     spring_date=spring_date)
  
  tmp_forecast <- WarmModelForecast(params = site_params, GDD=site_GDD, targets=site_targs, spring_date = spring_date,cross_validation = FALSE)
  tmp_forecast$siteID <- site
  tmp_forecast <- select(tmp_forecast,c(time=date,siteID,'gcc_90'=pred_gcc_90)) %>% 
    mutate(gcc_sd=NA,
           forecast_day=seq(1:nrow(.))) 
  forecast_df <- rbind(forecast_df,tmp_forecast)
  rm(tmp_forecast,site_params,site_targs,site_GDD)
  
}

```


# IV. Add uncertainty estimate
```{r addUncertainty}
error_df <- read_csv()


```


# V. Plot forecasted GCC with targets
```{r plotForecast}
# Read full targets DF in to rbind to forecasted gcc values and plot
targets <- read.csv(target_fp,header=TRUE) %>% 
  mutate(time = as.Date(time),
         source=as.factor("targets"),
         siteID = as.factor(siteID))
forecast_df$source<-"forecast"

all_gcc <- rbind(targets,forecast_df[,c(1:4,6)]) # Bind with targets, but skip forecast_day column

ggplot(all_gcc,aes(x=time,y=gcc_90))+
  geom_point(aes(color=source))+
  facet_wrap(~siteID)+
  theme_classic(base_size = 16)+
  scale_color_manual(values=c("grey","springgreen4"),labels=c("Observed","Forecasted"))+
  labs(x="Year",y="Green Chromatic Coordinate (GCC)",color="")
```


# VI. Get into correct format for succesful submission
```{r formatForSubmit}



```


# VII. Submit forecast
```{r submitForecast}

publish(code = c("phenology-workflow.R", "nullModel_randomWalk_main.R", "randomWalkNullModelFunction.R"),
        data_out = c(forecast_file_name),
        prefix = "phenology/",
        bucket = "forecasts")

```

